<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="naver-site-verification" content="760dcf2c928601f50f3941df3b6b4629fd244c7c" />
    <!-- Google Ads -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2182912223281192"
    crossorigin="anonymous"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-90VXCLXLJT"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-90VXCLXLJT');
    </script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-245679127-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-245679127-1');
    </script>

    

    
    <title>Making Chatbot with doc2vec tutorial(1) | Jang Minjee</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="Doc2vec,Chatbot,NLP" />
    
    <meta name="description" content="모델 만들기데이터 만들기doc2vec을 이용해서 FAQ데이터들의 질문들을 벡터화하는 모델을 만들어 본다. word2vec이 단어를 벡터화 하는 것이라면 doc2vec은 단어가 아니라 문서를 기준으로 (여기서는 문장)벡터를 만드는 라이브러리이다. doc2vec을 사용하면 서로 다른 문서들이 같은 차원의 벡터값을 갖게 된다. 각 문서라 갖는 벡터값을 비교해 같">
<meta property="og:type" content="article">
<meta property="og:title" content="Making Chatbot with doc2vec tutorial(1)">
<meta property="og:url" content="https://jmj3047.github.io/2022/05/06/Making_Chatbot_with_doc2vec_tutorial(1)/index.html">
<meta property="og:site_name" content="Jang Minjee">
<meta property="og:description" content="모델 만들기데이터 만들기doc2vec을 이용해서 FAQ데이터들의 질문들을 벡터화하는 모델을 만들어 본다. word2vec이 단어를 벡터화 하는 것이라면 doc2vec은 단어가 아니라 문서를 기준으로 (여기서는 문장)벡터를 만드는 라이브러리이다. doc2vec을 사용하면 서로 다른 문서들이 같은 차원의 벡터값을 갖게 된다. 각 문서라 갖는 벡터값을 비교해 같">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-05-05T15:00:00.000Z">
<meta property="article:modified_time" content="2022-10-15T08:07:56.742Z">
<meta property="article:author" content="Jang Minjee">
<meta property="article:tag" content="Doc2vec">
<meta property="article:tag" content="Chatbot">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
    

    

    
        <link rel="icon" href="/images/favicon.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.5.0/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=[object Object]"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '[object Object]');
</script>
<!-- End Google Analytics -->

    
    
    


    
<link rel="stylesheet" href="https://cdn.rawgit.com/innks/NanumSquareRound/master/nanumsquareround.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" target="_blank" rel="noopener" href="https://github.com/jmj3047/mj_portfolio">About Me</a>
                                </li>
                            
                                    <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Analysis/">Data Analysis</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Analysis/Basic/">Basic</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Analysis/Model/">Model</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Platform-Base/">Data Platform/Base</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Platform-Base/GCP/">GCP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Platform-Base/MongoDB/">MongoDB</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/">Paper</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Computer-Vision/">Computer Vision</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Generative-Model/">Generative Model</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Multi-Task-Learning/">Multi-Task Learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Speaker-Verification/">Speaker Verification</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Speech-Emotion-Recognition/">Speech Emotion Recognition</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Paper/Speech-Representations/">Speech Representations</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/Django/">Django</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/HTML/">HTML</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/Pyspark/">Pyspark</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/Python/">Python</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Setting/">Setting</a></li></ul>
                                
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Python/">Python</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/Python/Python/">Python</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Making_Chatbot_with_doc2vec_tutorial(1)" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Making Chatbot with doc2vec tutorial(1)
        </h1>
    

                
            </header>
        
        
            <div class="article-meta">
                
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2022/05/06/Making_Chatbot_with_doc2vec_tutorial(1)/" class="article-date">
       <time datetime="2022-05-05T15:00:00.000Z" itemprop="datePublished">2022-05-06</time>
    </a>
  </div>


<div class="article-date">
  <i class="fa fa-calendar-plus-o"></i>
  <a href="/2022/05/06/Making_Chatbot_with_doc2vec_tutorial(1)/" class="article-date">
     <time datetime="2022-10-15T08:07:56.742Z" itemprop="dateModified">2022-10-15</time>
  </a>
</div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/Chatbot/" rel="tag">Chatbot</a>, <a class="tag-link-link" href="/tags/Doc2vec/" rel="tag">Doc2vec</a>, <a class="tag-link-link" href="/tags/NLP/" rel="tag">NLP</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            

            

            

            <h2 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h2><h3 id="데이터-만들기"><a href="#데이터-만들기" class="headerlink" title="데이터 만들기"></a>데이터 만들기</h3><p>doc2vec을 이용해서 FAQ데이터들의 질문들을 벡터화하는 모델을 만들어 본다. word2vec이 단어를 벡터화 하는 것이라면 doc2vec은 단어가 아니라 문서를 기준으로 (여기서는 문장)벡터를 만드는 라이브러리이다. doc2vec을 사용하면 서로 다른 문서들이 같은 차원의 벡터값을 갖게 된다. 각 문서라 갖는 벡터값을 비교해 같으면 같을 수록 유사한 문서라는 것을 알 수 있다. </p>
<p>따라서 doc2vec을 이용해 FAQ의 질문들을 벡터화 한다면 어떤 질문이 들어왔을 때 동일 모델로 질문을 벡터화 한다음, 저장돼 있는 질문들의 벡터와 비교해서 가장 유사한 질문을 찾을 수 있다. 가장 유사한 질문을 찾은 다음 그 질문의 답을 출력하면 FAQ챗봇을 만들 수 있다. </p>
<p>**GPU사용 필수..!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> doc2vec</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> TaggedDocument</span><br><span class="line"></span><br><span class="line">faqs = [[<span class="string">&quot;1&quot;</span>, <span class="string">&quot;당해년도 납입액은 수정 가능 한가요?&quot;</span>, <span class="string">&quot;네, 당해년도 납입액은 12464 화면 등록전까지 수정 가능합니다.&quot;</span>],</span><br><span class="line">        [<span class="string">&quot;2&quot;</span>, <span class="string">&quot;대리인통보 대상계좌 기준은 어떻게 되나요?&quot;</span>, <span class="string">&quot;모계좌 기준 가장 최근에 개설된 계좌의 관리점에서 조회 됩니다.  의원폐쇄된 자계좌는 조회대상 계좌에서 제외됩니다. 계좌주 계좌가 사절원 계좌가 아닌 경우만 조회됩니다&quot;</span>],</span><br><span class="line">        [<span class="string">&quot;3&quot;</span>, <span class="string">&quot;등록가능 단말기수는 어떻게 되나요?&quot;</span>, <span class="string">&quot;5대까지 등록 가능입니다.&quot;</span>],</span><br><span class="line">        [<span class="string">&quot;4&quot;</span>, <span class="string">&quot;모바일계좌개설 가능한 시간은 어떻게 되나요?&quot;</span>, <span class="string">&quot;08:00 ~ 20:00(영업일만 가능&quot;</span>],</span><br><span class="line">        [<span class="string">&quot;5&quot;</span>, <span class="string">&quot;미국인일때 미국납세자등록번호 작성 방법은 어떻게 되나요?&quot;</span>, <span class="string">&quot;계좌주가 미국인일 때 계좌주의 미국납세자등록번호(사회보장번호(Social Security Number), 고용주식별번호(Employer Identification Number), 개인납세자번호(Individual Taxpayer Identification Number))를 기재합니다..&quot;</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>위와 같이 5개의 FAQ데이터를 임의로 만들었다. 이제 여기에 5개의 질문을 벡터화 할건데 사실 벡터화 할 때 데이터는 많을 수록 좋다. 적으면 서로 분간이 잘 안됨. </p>
<h3 id="형태소-분석"><a href="#형태소-분석" class="headerlink" title="형태소 분석"></a>형태소 분석</h3><p>doc2vec으로 문장을 벡터화하기 전에 약간의 전처리 과정이 필요하다. 각 문장을 tokenize해야 한다. 토큰화 하는 과정이 영어랑 한국어랑 조금 다른데 한국어의 경우 형태소 분석(pos tagging)을 통해 형태소 단위로 나눈뒤 토큰으로 사용할 형태소를 결정하고 나눈다. 즉 각 문장을 형태소 단위의 배열로 만든다. </p>
<p>한국어 형태소 분석기는 konlpy를 사용한다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#형태소 분석</span></span><br><span class="line"><span class="keyword">import</span> jpype</span><br><span class="line"><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Kkma</span><br><span class="line"></span><br><span class="line">kkma = Kkma()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_kkma</span>(<span class="params">doc</span>):</span><br><span class="line">    jpype.attachThreadToJVM() <span class="comment">#자바를 사용하기 위한 소스 코드</span></span><br><span class="line">    token_doc = [<span class="string">&#x27;/&#x27;</span>.join(word) <span class="keyword">for</span> word <span class="keyword">in</span> kkma.pos(doc) ] <span class="comment">#형태소 분석한 단어와 형태소 명을 &#x27;단어/형태소&#x27;형태로 출력하기 위한 코드</span></span><br><span class="line">    <span class="keyword">return</span> token_doc</span><br><span class="line"></span><br><span class="line">tokenize_kkma(faqs[<span class="number">0</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>Kkma를 import 하고 jpype도 import 한다. jpype는 파이썬에서 자바를 사용할 수 있게 해주는 패키지인데 기본적으로 kkma가 자바 베이스라서 꼭 필요하다. Kkma()로 형태소 분석기를 불러온다음 kkma.pos(doc)로 형태소 분석을 한다. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">출력 결과:</span><br><span class="line"></span><br><span class="line">[&#x27;당해/NNG&#x27;,</span><br><span class="line"> &#x27;년도/NNM&#x27;,</span><br><span class="line"> &#x27;납입/NNG&#x27;,</span><br><span class="line"> &#x27;액/XSN&#x27;,</span><br><span class="line"> &#x27;은/JX&#x27;,</span><br><span class="line"> &#x27;수정/NNG&#x27;,</span><br><span class="line"> &#x27;가능/NNG&#x27;,</span><br><span class="line"> &#x27;한/MDN&#x27;,</span><br><span class="line"> &#x27;가요/NNG&#x27;,</span><br><span class="line"> &#x27;?/SF&#x27;]</span><br></pre></td></tr></table></figure>

<p>형태소 분석을 하면 문장이 단어&#x2F;형태소 형태의 배열로 출력된다. 1번 문장은 총 10개의 형태소로 나뉘었다. 형태소 분석기종류에 따라 결과가 조금씩 다를수 있다. </p>
<h3 id="Doc2Vec-모델-만들기"><a href="#Doc2Vec-모델-만들기" class="headerlink" title="Doc2Vec 모델 만들기"></a>Doc2Vec 모델 만들기</h3><p>Doc2Vec을 이용해 모델을 만들기 위해서는 토큰화 된 리스트와 태그 값이 필요하다. 여기서 태그는 문장 번호. [문장의 번호, 문장을 토큰화한 배열] 이렇게 두 개의 값을 가진 리스트를 사용해 doc2vec 모델을 만들 수 있다. 실제로 모델을 만드는데 사용하는 건 토큰 값이지만 비슷한 문장이 무엇인지 찾기 위한 인덱스로 태그 값을 사용하게 된다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 리스트에서 각 문장부분 토큰화</span></span><br><span class="line">token_faqs = [(tokenize_kkma(row[<span class="number">1</span>]), row[<span class="number">0</span>]) <span class="keyword">for</span> row <span class="keyword">in</span> faqs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Doc2Vec에서 사용하는 태그문서형으로 변경</span></span><br><span class="line">tagged_faqs = [TaggedDocument(d, [c]) <span class="keyword">for</span> d, c <span class="keyword">in</span> token_faqs]</span><br><span class="line"></span><br><span class="line">tagged_faqs</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[TaggedDocument(words=[&#x27;당해/NNG&#x27;, &#x27;년도/NNM&#x27;, &#x27;납입/NNG&#x27;, &#x27;액/XSN&#x27;, &#x27;은/JX&#x27;, &#x27;수정/NNG&#x27;, &#x27;가능/NNG&#x27;, &#x27;한/MDN&#x27;, &#x27;가요/NNG&#x27;, &#x27;?/SF&#x27;], tags=[&#x27;1&#x27;]),</span><br><span class="line"> TaggedDocument(words=[&#x27;대리인/NNG&#x27;, &#x27;통보/NNG&#x27;, &#x27;대상/NNG&#x27;, &#x27;계좌/NNG&#x27;, &#x27;기준/NNG&#x27;, &#x27;은/JX&#x27;, &#x27;어떻/VA&#x27;, &#x27;게/ECD&#x27;, &#x27;되/VV&#x27;, &#x27;나요/EFQ&#x27;, &#x27;?/SF&#x27;], tags=[&#x27;2&#x27;]),</span><br><span class="line"> TaggedDocument(words=[&#x27;등록/NNG&#x27;, &#x27;가능/NNG&#x27;, &#x27;단말/NNG&#x27;, &#x27;기수/NNG&#x27;, &#x27;는/JX&#x27;, &#x27;어떻/VA&#x27;, &#x27;게/ECD&#x27;, &#x27;되/VV&#x27;, &#x27;나요/EFQ&#x27;, &#x27;?/SF&#x27;], tags=[&#x27;3&#x27;]),</span><br><span class="line"> TaggedDocument(words=[&#x27;모바일/NNG&#x27;, &#x27;계좌/NNG&#x27;, &#x27;개설/NNG&#x27;, &#x27;가능/NNG&#x27;, &#x27;하/XSV&#x27;, &#x27;ㄴ/ETD&#x27;, &#x27;시간/NNG&#x27;, &#x27;은/JX&#x27;, &#x27;어떻/VA&#x27;, &#x27;게/ECD&#x27;, &#x27;되/VV&#x27;, &#x27;나요/EFQ&#x27;, &#x27;?/SF&#x27;], tags=[&#x27;4&#x27;]),</span><br><span class="line"> TaggedDocument(words=[&#x27;미국인/NNG&#x27;, &#x27;일/NNG&#x27;, &#x27;때/NNG&#x27;, &#x27;미국/NNP&#x27;, &#x27;납세자/NNG&#x27;, &#x27;등록/NNG&#x27;, &#x27;번호/NNG&#x27;, &#x27;작성/NNG&#x27;, &#x27;방법/NNG&#x27;, &#x27;은/JX&#x27;, &#x27;어떻/VA&#x27;, &#x27;게/ECD&#x27;, &#x27;되/VV&#x27;, &#x27;나요/EFQ&#x27;, &#x27;?/SF&#x27;], tags=[&#x27;5&#x27;])]</span><br></pre></td></tr></table></figure>

<p>TaggedDocument function을 사용하면 doc2vec에서 사용할 수 있는 태그 된 문서 형식으로 변경한다. 출력해 보면 words배열과 tags값을 갖는 Dic형태의 자료형이 되었음을 확인할 수 있다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make model</span></span><br><span class="line">    <span class="keyword">import</span> multiprocessing</span><br><span class="line">    cores = multiprocessing.cpu_count()</span><br><span class="line">    d2v_faqs = doc2vec.Doc2Vec(vector_size=<span class="number">50</span>, </span><br><span class="line">                            alpha=<span class="number">0.025</span>,</span><br><span class="line">                            min_alpha=<span class="number">0.025</span>,</span><br><span class="line">                            hs=<span class="number">1</span>,</span><br><span class="line">                            negative=<span class="number">0</span>,</span><br><span class="line">                            dm=<span class="number">0</span>,</span><br><span class="line">                            dbow_words = <span class="number">1</span>,</span><br><span class="line">                            min_count = <span class="number">1</span>,</span><br><span class="line">                            workers = cores,</span><br><span class="line">                            seed=<span class="number">0</span>)</span><br><span class="line">    d2v_faqs.build_vocab(tagged_faqs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train document vectors</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        d2v_faqs.train(tagged_faqs,</span><br><span class="line">                                   total_examples = d2v_faqs.corpus_count,</span><br><span class="line">                                   epochs = d2v_faqs.epochs</span><br><span class="line">                                   )</span><br><span class="line">        d2v_faqs.alpha -= <span class="number">0.0025</span> <span class="comment"># decrease the learning rate</span></span><br><span class="line">        d2v_faqs.min_alpha = d2v_faqs.alpha <span class="comment"># fix the learning rate, no decay</span></span><br></pre></td></tr></table></figure>

<p>모델을 만들고 학습 시킨다. </p>
<p>doc2vec모델을 만들 때 파라미터는 여러가지가 들어가는데 여기서는 vector_size와 min_count정도를 수정했다. vector_size는 만들어지는 벡터 차원의 크기이고, min_count는 최소 몇 번 이상 나온 단어에 대해 학습할지 정하는 파라미터이다. 여기서는 일단 사이즈 50에 최소 횟수는 1회로 정했다. epoch는 10번으로 해서 train했다. </p>
<h3 id="유사-문장-찾기"><a href="#유사-문장-찾기" class="headerlink" title="유사 문장 찾기"></a>유사 문장 찾기</h3><p>이제 이 모델로 어떤 문장이 들어왔을 때 1~5번 중에 무엇과 비슷한지 알아보자. 먼저 어떤 문장이 들어오면 그 문장을 벡터화 하고 그 벡터가 어떤 문장과 비슷한지 태그 값을 찾아본다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predict_vector = d2v_faqs.infer_vector([<span class="string">&quot;당해년도 납입액은 수정 가능 한가요?&quot;</span>])</span><br><span class="line">d2v_faqs.docvecs.most_similar([predict_vector], topn=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#x27;2&#x27;, 0.21605531871318817), (&#x27;3&#x27;, 0.10707802325487137)]</span><br></pre></td></tr></table></figure>

<p>제대로 됐는지 확인하기 위해 1번 문장을 그대로 넣었지만 답은 2, 3번이 나왔다. 학습이 제대로 되지 않아서 이런 결과가 나왔다. </p>
<p>테스트할 문장을 벡터화 할 때도 형태소 분석을 해줘야 한다. 왜냐하면 모델을 학습 할 때 문장들을 형태소로 분석해서 넣어줬기 때문이다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_string = <span class="string">&quot;대리인통보 대상계좌 기준은 어떻게 되나요?&quot;</span></span><br><span class="line">tokened_test_string = tokenize_kkma(test_string)</span><br><span class="line">tokened_test_string</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;대리인/NNG&#x27;,</span><br><span class="line"> &#x27;통보/NNG&#x27;,</span><br><span class="line"> &#x27;대상/NNG&#x27;,</span><br><span class="line"> &#x27;계좌/NNG&#x27;,</span><br><span class="line"> &#x27;기준/NNG&#x27;,</span><br><span class="line"> &#x27;은/JX&#x27;,</span><br><span class="line"> &#x27;어떻/VA&#x27;,</span><br><span class="line"> &#x27;게/ECD&#x27;,</span><br><span class="line"> &#x27;되/VV&#x27;,</span><br><span class="line"> &#x27;나요/EFQ&#x27;,</span><br><span class="line"> &#x27;?/SF&#x27;]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_vector = d2v_faqs.infer_vector(tokened_test_string)</span><br><span class="line">d2v_faqs.docvecs.most_similar([test_vector], topn=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#x27;1&#x27;, 0.1448383331298828), (&#x27;3&#x27;, 0.0218462273478508)]</span><br></pre></td></tr></table></figure>

<p>2번 문장으로 했을 때 결과입니다. </p>
<p>doc2vec이라는 모델은 문서단위로 벡터화 하는 것이기 때문에 문서가 많아야 한다. 여기서는 문장이 많아야 한다. 문장이 많으면 많을 수록 문장 간의 거리를 계산해서 더 잘 구분해준다. 간단하게 생각하면 문장이 적으면 적중률이 높을 것 같지만 사실은 그 반대이다. 데이터가 많을수록 그 데이터간의 차이를 구분할 수 있기 때문에 더 잘 예측하게 된다. </p>
<hr>
<ul>
<li>Local path :C:\Users\jmj30\Dropbox\카메라 업로드\Documentation\2022\2022 상반기\휴먼교육센터\mj_chatbot_prac\faq_chatbot</li>
<li>Reference: <a target="_blank" rel="noopener" href="https://cholol.tistory.com/466">https://cholol.tistory.com/466</a></li>
</ul>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://jmj3047.github.io/2022/05/06/Making_Chatbot_with_doc2vec_tutorial(1)/" data-id="cllsxv88g005xmsu6amchgyya" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "Jang Minjee"
        },
        "headline": "Making Chatbot with doc2vec tutorial(1)",
        "image": "https://jmj3047.github.io",
        "keywords": "Doc2vec Chatbot NLP",
        "genre": "Python Python",
        "datePublished": "2022-05-06",
        "dateCreated": "2022-05-06",
        "dateModified": "2022-10-15",
        "url": "https://jmj3047.github.io/2022/05/06/Making_Chatbot_with_doc2vec_tutorial(1)/",
        "description": "모델 만들기데이터 만들기doc2vec을 이용해서 FAQ데이터들의 질문들을 벡터화하는 모델을 만들어 본다. word2vec이 단어를 벡터화 하는 것이라면 doc2vec은 단어가 아니라 문서를 기준으로 (여기서는 문장)벡터를 만드는 라이브러리이다. doc2vec을 사용하면 서로 다른 문서들이 같은 차원의 벡터값을 갖게 된다. 각 문서라 갖는 벡터값을 비교해 같",
        "wordCount": 1513
    }
</script>

</article>

    <section id="comments">
    
    </section>



                        </div>
                    </section>
                    
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/jmj3047" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="dropbox" href="https://www.dropbox.com/home" target="_blank" rel="noopener">
                        <i class="icon fa fa-dropbox"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="google" href="https://www.google.com" target="_blank" rel="noopener">
                        <i class="icon fa fa-google"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="youtube" href="https://www.youtube.com/" target="_blank" rel="noopener">
                        <i class="icon fa fa-youtube"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="discord" href="https://discord.com/channels/@me" target="_blank" rel="noopener">
                        <i class="icon fa fa-discord"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
<!-- 
    <div class="github-card" data-github="jmj3047" data-width="400" data-height="" data-theme="default">
    </div>
    <script src="//cdn.jsdelivr.net/github-cards/latest/widget.js">    </script> -->

    
        
<nav id="article-nav">
    
        <a href="/2022/05/10/LGBM/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Light Gradient Boosting Machine
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2022/05/06/Making_English_Chatbot_with_Django(4)/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Making English Chatbot with Django(4)</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    


    <div class="widgets-container">
        
        
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Paper/">Paper</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a></p>
                            <p class="item-title"><a href="/2024/06/14/PAPT_SER/" class="title">Personalized Adaptation with Pre-trained Speech Encoders for Continuous Emotion Recognition</a></p>
                            <p class="item-date"><time datetime="2024-06-13T15:00:00.000Z" itemprop="datePublished">2024-06-14</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Paper/">Paper</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a></p>
                            <p class="item-title"><a href="/2024/04/08/EMOFSL_for_cross_corpus_SER/" class="title">Few Shot Learning Guided by Emotion Distance for Cross-corpus Speech Emotion Recognition</a></p>
                            <p class="item-date"><time datetime="2024-04-07T15:00:00.000Z" itemprop="datePublished">2024-04-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Paper/">Paper</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a></p>
                            <p class="item-title"><a href="/2024/02/20/Transductive_Inductive/" class="title">Transductive learning VS Inductive Learning</a></p>
                            <p class="item-date"><time datetime="2024-02-19T15:00:00.000Z" itemprop="datePublished">2024-02-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Paper/">Paper</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a></p>
                            <p class="item-title"><a href="/2024/01/29/MTL_for_FSL/" class="title">Meta Transfer Learning for Few Shot Learning</a></p>
                            <p class="item-date"><time datetime="2024-01-28T15:00:00.000Z" itemprop="datePublished">2024-01-29</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Paper/">Paper</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Paper/Speech-Emotion-Recognition/">Speech Emotion Recognition</a></p>
                            <p class="item-title"><a href="/2023/11/07/Speaker_to_Emotion/" class="title">Speaker to Emotion, Domain Adaptation for Speech Emotion Recognition with Residual Adapters</a></p>
                            <p class="item-date"><time datetime="2023-11-06T15:00:00.000Z" itemprop="datePublished">2023-11-07</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Analysis/">Data Analysis</a><span class="category-list-count">40</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Analysis/Basic/">Basic</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Analysis/Model/">Model</a><span class="category-list-count">16</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Platform-Base/">Data Platform/Base</a><span class="category-list-count">16</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Platform-Base/GCP/">GCP</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Platform-Base/MongoDB/">MongoDB</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a><span class="category-list-count">29</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Computer-Vision/">Computer Vision</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Few-Shot-Learning/">Few Shot Learning</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Generative-Model/">Generative Model</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Multi-Task-Learning/">Multi-Task Learning</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/NLP/">NLP</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Speaker-Verification/">Speaker Verification</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Speech-Emotion-Recognition/">Speech Emotion Recognition</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/Speech-Representations/">Speech Representations</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">15</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Django/">Django</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/HTML/">HTML</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Pyspark/">Pyspark</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Python/">Python</a><span class="category-list-count">5</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Setting/">Setting</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/ACF/" style="font-size: 10px;">ACF</a> <a href="/tags/AI-Studies/" style="font-size: 15.83px;">AI Studies</a> <a href="/tags/AI-tool/" style="font-size: 10px;">AI tool</a> <a href="/tags/ARIMA/" style="font-size: 10px;">ARIMA</a> <a href="/tags/Acoustic-Parameter-Set/" style="font-size: 10px;">Acoustic Parameter Set</a> <a href="/tags/Adaptation/" style="font-size: 10px;">Adaptation</a> <a href="/tags/Adversarial-Domain-Adaptation/" style="font-size: 10px;">Adversarial Domain Adaptation</a> <a href="/tags/Adversarial-Speaker-Verification/" style="font-size: 10px;">Adversarial Speaker Verification</a> <a href="/tags/Attention/" style="font-size: 10.83px;">Attention</a> <a href="/tags/Auth/" style="font-size: 10px;">Auth</a> <a href="/tags/Automation/" style="font-size: 10px;">Automation</a> <a href="/tags/Bash/" style="font-size: 10px;">Bash</a> <a href="/tags/BeautifulSoup/" style="font-size: 11.67px;">BeautifulSoup</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Bi-Encoder/" style="font-size: 10px;">Bi Encoder</a> <a href="/tags/Big-Query/" style="font-size: 15px;">Big Query</a> <a href="/tags/BigQueryML/" style="font-size: 14.17px;">BigQueryML</a> <a href="/tags/Brython/" style="font-size: 10px;">Brython</a> <a href="/tags/CGI/" style="font-size: 10px;">CGI</a> <a href="/tags/Center-Loss/" style="font-size: 10px;">Center Loss</a> <a href="/tags/Chatbot/" style="font-size: 13.33px;">Chatbot</a> <a href="/tags/Clustering/" style="font-size: 14.17px;">Clustering</a> <a href="/tags/Confusion-Matrix/" style="font-size: 10px;">Confusion Matrix</a> <a href="/tags/Convolutional-Neural-Networks/" style="font-size: 10.83px;">Convolutional Neural Networks</a> <a href="/tags/Coursera/" style="font-size: 18.33px;">Coursera</a> <a href="/tags/Cross-Encoder/" style="font-size: 10px;">Cross Encoder</a> <a href="/tags/Cross-domain/" style="font-size: 10px;">Cross-domain</a> <a href="/tags/DBSCAN/" style="font-size: 10px;">DBSCAN</a> <a href="/tags/DCGAN/" style="font-size: 10px;">DCGAN</a> <a href="/tags/DataFlow/" style="font-size: 10px;">DataFlow</a> <a href="/tags/Decision-Tree-Classifier/" style="font-size: 10px;">Decision Tree Classifier</a> <a href="/tags/Deep-Nueral-Networks/" style="font-size: 10.83px;">Deep Nueral Networks</a> <a href="/tags/Deep-Machine-Learning-Paper-Study/" style="font-size: 17.5px;">Deep/Machine Learning Paper Study</a> <a href="/tags/Doc2vec/" style="font-size: 12.5px;">Doc2vec</a> <a href="/tags/Domain-Adaptation/" style="font-size: 10.83px;">Domain Adaptation</a> <a href="/tags/Domain-Adversarial-Layer/" style="font-size: 10px;">Domain Adversarial Layer</a> <a href="/tags/Domain-Invariant-Feature-Learning/" style="font-size: 10.83px;">Domain Invariant Feature Learning</a> <a href="/tags/English/" style="font-size: 19.17px;">English</a> <a href="/tags/Ensemble-Model/" style="font-size: 10px;">Ensemble Model</a> <a href="/tags/Error/" style="font-size: 10px;">Error</a> <a href="/tags/Evaluation/" style="font-size: 10px;">Evaluation</a> <a href="/tags/F1-measure/" style="font-size: 10px;">F1 measure</a> <a href="/tags/Few-Shot-Learning/" style="font-size: 10.83px;">Few Shot Learning</a> <a href="/tags/Flask/" style="font-size: 10px;">Flask</a> <a href="/tags/GAN/" style="font-size: 10.83px;">GAN</a> <a href="/tags/GCP/" style="font-size: 10px;">GCP</a> <a href="/tags/Gaussian-Mixture-Model/" style="font-size: 10.83px;">Gaussian Mixture Model</a> <a href="/tags/Gen-App-Builder/" style="font-size: 10px;">Gen App Builder</a> <a href="/tags/Generative-Adversarial-Network/" style="font-size: 10px;">Generative Adversarial Network</a> <a href="/tags/Generative-Model/" style="font-size: 10px;">Generative Model</a> <a href="/tags/Git/" style="font-size: 10.83px;">Git</a> <a href="/tags/Grid-Search-CV/" style="font-size: 10px;">Grid Search CV</a> <a href="/tags/HTML/" style="font-size: 11.67px;">HTML</a> <a href="/tags/Hexo/" style="font-size: 12.5px;">Hexo</a> <a href="/tags/HuBERT/" style="font-size: 10px;">HuBERT</a> <a href="/tags/Hueman/" style="font-size: 10px;">Hueman</a> <a href="/tags/Image-Classification/" style="font-size: 11.67px;">Image Classification</a> <a href="/tags/Inductive-Learning/" style="font-size: 10px;">Inductive Learning</a> <a href="/tags/K-Means-Clustering/" style="font-size: 11.67px;">K-Means Clustering</a> <a href="/tags/Kaggle/" style="font-size: 10px;">Kaggle</a> <a href="/tags/Looker-Studio/" style="font-size: 11.67px;">Looker Studio</a> <a href="/tags/ML-Analysis/" style="font-size: 20px;">ML Analysis</a> <a href="/tags/ML-Operations/" style="font-size: 10.83px;">ML Operations</a> <a href="/tags/ML-Process/" style="font-size: 10.83px;">ML Process</a> <a href="/tags/Meta-Transfer-Learning/" style="font-size: 10px;">Meta Transfer Learning</a> <a href="/tags/Metric-Learning/" style="font-size: 10px;">Metric Learning</a> <a href="/tags/Model-Generalization/" style="font-size: 10px;">Model Generalization</a> <a href="/tags/MongoDB/" style="font-size: 11.67px;">MongoDB</a> <a href="/tags/Multi-Task-Learning/" style="font-size: 10.83px;">Multi-Task Learning</a> <a href="/tags/NLP/" style="font-size: 13.33px;">NLP</a> <a href="/tags/Nonprobability-sampling/" style="font-size: 10px;">Nonprobability sampling</a> <a href="/tags/Normal-Distribution/" style="font-size: 10px;">Normal Distribution</a> <a href="/tags/PACF/" style="font-size: 10px;">PACF</a> <a href="/tags/Pandas-Dataframe/" style="font-size: 10px;">Pandas Dataframe</a> <a href="/tags/Personalization/" style="font-size: 10px;">Personalization</a> <a href="/tags/Precision-Recall/" style="font-size: 10px;">Precision-Recall</a> <a href="/tags/Probabilistic-sampling/" style="font-size: 10px;">Probabilistic sampling</a> <a href="/tags/Probability-Density-Function/" style="font-size: 10px;">Probability Density Function</a> <a href="/tags/Probability-Distribution-Function/" style="font-size: 10px;">Probability Distribution Function</a> <a href="/tags/Python/" style="font-size: 15.83px;">Python</a> <a href="/tags/Quiz/" style="font-size: 15px;">Quiz</a> <a href="/tags/ROC-curve/" style="font-size: 10px;">ROC curve</a> <a href="/tags/Recommendation-System/" style="font-size: 10.83px;">Recommendation System</a> <a href="/tags/Representation-Learning/" style="font-size: 10px;">Representation Learning</a> <a href="/tags/Self-Supervised-Features/" style="font-size: 10px;">Self-Supervised Features</a> <a href="/tags/Self-Supervised-Learning/" style="font-size: 11.67px;">Self-Supervised Learning</a> <a href="/tags/Sentence-Bert/" style="font-size: 10px;">Sentence Bert</a> <a href="/tags/Speaker-GAN/" style="font-size: 10px;">Speaker GAN</a> <a href="/tags/Speaker-Identification/" style="font-size: 10px;">Speaker Identification</a> <a href="/tags/Speaker-Independent/" style="font-size: 10px;">Speaker Independent</a> <a href="/tags/Speaker-Normalization/" style="font-size: 10px;">Speaker Normalization</a> <a href="/tags/Speaker-Verification/" style="font-size: 10px;">Speaker Verification</a> <a href="/tags/Speaker-Verification/" style="font-size: 10px;">Speaker Verification,</a> <a href="/tags/Speech-Emotion-Recognition/" style="font-size: 16.67px;">Speech Emotion Recognition</a> <a href="/tags/Speech-Feature-Extraction/" style="font-size: 10px;">Speech Feature Extraction</a> <a href="/tags/Speech-Representations/" style="font-size: 10px;">Speech Representations</a> <a href="/tags/Spoken-Language-Understanding/" style="font-size: 10px;">Spoken Language Understanding</a> <a href="/tags/Standard-Normal-Distribution/" style="font-size: 10px;">Standard Normal Distribution</a> <a href="/tags/TD-SV/" style="font-size: 10px;">TD-SV</a> <a href="/tags/Threshold-Adjustment/" style="font-size: 10px;">Threshold Adjustment</a> <a href="/tags/Time-Series/" style="font-size: 10px;">Time Series</a> <a href="/tags/Transductive-Learning/" style="font-size: 10px;">Transductive Learning</a> <a href="/tags/Transfer-Learning/" style="font-size: 10px;">Transfer Learning</a> <a href="/tags/Transformer/" style="font-size: 11.67px;">Transformer</a> <a href="/tags/Vertex-AI/" style="font-size: 10px;">Vertex AI</a> <a href="/tags/Virtualenv/" style="font-size: 10px;">Virtualenv</a> <a href="/tags/Voice-Trigger-Detection/" style="font-size: 10.83px;">Voice Trigger Detection</a> <a href="/tags/WGAN/" style="font-size: 10px;">WGAN</a> <a href="/tags/WGAN-GP/" style="font-size: 10px;">WGAN-GP</a> <a href="/tags/Wake-Up-Words/" style="font-size: 10px;">Wake-Up Words</a> <a href="/tags/Wav2vec-2-0/" style="font-size: 10px;">Wav2vec 2.0</a> <a href="/tags/Web-Crawling/" style="font-size: 11.67px;">Web Crawling</a> <a href="/tags/Web-Server/" style="font-size: 10.83px;">Web Server</a> <a href="/tags/kaggle/" style="font-size: 10px;">kaggle</a> <a href="/tags/pyspark/" style="font-size: 12.5px;">pyspark</a>
        </div>
    </div>


            
        

    </div>
</aside>


                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2024 Jang Minjee</p>
                
                <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="https://github.com/ppoffice" target="_blank">PPOffice</a></p>
                
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

    </div>
    


    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    
      <script data-ad-client="ca-pub-2182912223281192" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

    
    
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


</body>
</html>
